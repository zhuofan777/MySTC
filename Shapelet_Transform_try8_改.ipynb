{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import heapq as hq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 计算方差窗口的大小\n",
    "def computeWinSize(length, b):\n",
    "    if 0 < length <= b:\n",
    "        return 1\n",
    "    else:\n",
    "        return length // b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 计算标准差数组\n",
    "def computeStdArr(series, b):\n",
    "    l = len(series)\n",
    "    # 窗口下取整\n",
    "    w = computeWinSize(l, b)\n",
    "    # print(w)\n",
    "    res = []\n",
    "    for i in range(w, l - w):\n",
    "        win_arr = [0 for i in range(2 * w + 1)]\n",
    "        cnt = 0\n",
    "        for j in range(i - w, w + i + 1):\n",
    "            win_arr[cnt] = series[j]\n",
    "            cnt += 1\n",
    "        std = np.std(win_arr, ddof=0)\n",
    "        res.append(std)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 选择L*α最大的点的下标,，保留下标\n",
    "def selectLargePoint(series, a):\n",
    "    l = len(series)\n",
    "    # 生成l*a个\n",
    "    res = hq.nlargest(int(l * a), range(l), key=lambda x: series[x])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 判断是否为波峰波谷\n",
    "def isPeakOrValley(std_arr, index, b):\n",
    "    win_size = computeWinSize(len(std_arr), b)\n",
    "    flag = False\n",
    "    if win_size == 1:\n",
    "        if ((std_arr[index] > std_arr[index - 1] and std_arr[index] > std_arr[index + 1]) or (\n",
    "                std_arr[index] < std_arr[index - 1] and std_arr[index] < std_arr[index + 1])):\n",
    "            flag = True\n",
    "    elif win_size == 2:\n",
    "        if ((std_arr[index] >= std_arr[index - 1] and std_arr[index] > std_arr[index - 2] and std_arr[index] >= std_arr[\n",
    "            index + 1] and std_arr[index] > std_arr[index + 2])\n",
    "                or\n",
    "                (std_arr[index] <= std_arr[index - 1] and std_arr[index] < std_arr[index - 2] and std_arr[index] <=\n",
    "                 std_arr[\n",
    "                     index + 1]) and std_arr[index] < std_arr[index + 2]):\n",
    "            flag = True\n",
    "    elif win_size == 3:\n",
    "        if ((std_arr[index] >= std_arr[index - 1] and std_arr[index] > std_arr[index - 2] and std_arr[index] > std_arr[\n",
    "            index - 3]\n",
    "             and std_arr[index] >= std_arr[index + 1] and std_arr[index] > std_arr[index + 2] and std_arr[index] >\n",
    "             std_arr[\n",
    "                 index + 3])\n",
    "                or\n",
    "                (std_arr[index] <= std_arr[index - 1] and std_arr[index] < std_arr[index - 2] and std_arr[index] <\n",
    "                 std_arr[index - 3]) and std_arr[index] <= std_arr[index + 1] and std_arr[index] < std_arr[\n",
    "                    index + 2] and std_arr[index] < std_arr[index + 3]):\n",
    "            flag = True\n",
    "    elif win_size == 4:\n",
    "        if ((std_arr[index] >= std_arr[index - 1] and std_arr[index] > std_arr[index - 2] and std_arr[index] > std_arr[\n",
    "            index - 3] and std_arr[index] > std_arr[index - 4]\n",
    "             and std_arr[index] >= std_arr[index + 1] and std_arr[index] > std_arr[index + 2] and std_arr[index] >\n",
    "             std_arr[\n",
    "                 index + 3] and std_arr[index] > std_arr[index + 4])\n",
    "                or\n",
    "                (std_arr[index] <= std_arr[index - 1] and std_arr[index] < std_arr[index - 2] and std_arr[index] <\n",
    "                 std_arr[\n",
    "                     index - 3] and std_arr[index] < std_arr[index - 4]\n",
    "                 and std_arr[index] <= std_arr[index + 1] and std_arr[index] < std_arr[index + 2] and std_arr[index] <\n",
    "                 std_arr[index + 3] and std_arr[index] < std_arr[index + 4])):\n",
    "            flag = True\n",
    "    else:\n",
    "        if ((std_arr[index] > std_arr[index - 1] and std_arr[index] > std_arr[index - 2] and std_arr[index] > std_arr[\n",
    "            index - 3] and std_arr[index] > std_arr[index - 4] and std_arr[index] > std_arr[index - 5]\n",
    "             and std_arr[index] > std_arr[index + 1] and std_arr[index] > std_arr[index + 2] and std_arr[index] >\n",
    "             std_arr[\n",
    "                 index + 3] and std_arr[index] > std_arr[index + 4] and std_arr[index] > std_arr[index + 5])\n",
    "                or\n",
    "                (std_arr[index] < std_arr[index - 1] and std_arr[index] < std_arr[index - 2] and std_arr[index] <\n",
    "                 std_arr[\n",
    "                     index - 3] and std_arr[index] < std_arr[index - 4] and std_arr[index] < std_arr[index - 5]\n",
    "                 and std_arr[index] < std_arr[index + 1] and std_arr[index] < std_arr[index + 2] and std_arr[index] <\n",
    "                 std_arr[\n",
    "                     index + 3] and std_arr[index] < std_arr[index + 4] and std_arr[index] < std_arr[index + 5])):\n",
    "            flag = True\n",
    "    return flag\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 找到所有合适的区间\n",
    "def fitPoint(stdA, indexA, b):\n",
    "    w = computeWinSize(len(stdA), b)\n",
    "    l = len(indexA)\n",
    "    res = []\n",
    "    for i in range(0, l):\n",
    "        val = indexA[i]\n",
    "        if w <= val < l - w:\n",
    "            if isPeakOrValley(stdA, val, b):\n",
    "                res.append(val + 2 * w + 1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 提取特征关键点\n",
    "def extractFeaturePoint(arr, a, b):\n",
    "    stdArrOne = computeStdArr(arr, b)\n",
    "    largePoint = selectLargePoint(stdArrOne, a)\n",
    "    indexArr = fitPoint(stdArrOne, largePoint, b)\n",
    "    return indexArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 判断有几个关键点与它相近\n",
    "def closeNums(keyList,key,threshold):\n",
    "    cnt = 0\n",
    "    cnt += keyList.count(key)\n",
    "    for i in range(1,threshold):\n",
    "        a = key + i\n",
    "        b = key - i\n",
    "        cnt += keyList.count(a)\n",
    "        cnt += keyList.count(b)\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class keyPoint:\n",
    "    def __init__(self,key,cnt,dim):\n",
    "        self.key = key\n",
    "        self.cnt = cnt\n",
    "        self.dim = dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class smallKeyPoint:\n",
    "    def __init__(self,key,dim):\n",
    "        self.key = key\n",
    "        self.dim = dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 找到较为相近的关键点\n",
    "def selectKeys(data,alp,blt,howclose=2):\n",
    "    # 原始data顺序 样本数 维度数 序列长度\n",
    "    dim_nums = data.shape[1]\n",
    "    sample_nums = data.shape[0]\n",
    "    all_keys = []\n",
    "    for sm in tqdm(range(sample_nums)):\n",
    "        one_sample  = data[sm]\n",
    "        # 每个维度的关键点下标集合\n",
    "        key_points = []\n",
    "        # 所为维度下的关键点下标\n",
    "        ex_key_points = []\n",
    "        for dn in range(dim_nums):\n",
    "            # keys 关键点的下标\n",
    "            keys = extractFeaturePoint(one_sample[dn],alp,blt)\n",
    "            key_points.append(keys)\n",
    "        # 有一部分在构建的序列上\n",
    "\n",
    "        for dn in range(dim_nums):\n",
    "            # 一个维度上的关键下标\n",
    "            kl = key_points[dn]\n",
    "            # 去掉自己维度的下标\n",
    "            tmp_key_points = key_points[:]\n",
    "            tmp_key_points.remove(kl)\n",
    "            key_list = []\n",
    "            for i in tmp_key_points:\n",
    "                key_list.extend(i)\n",
    "\n",
    "            ekl = []\n",
    "            for k in kl:\n",
    "                cnt = closeNums(key_list,k,howclose)\n",
    "                ekl.append(keyPoint(k,cnt,dn))\n",
    "            ex_key_points.extend(ekl)\n",
    "\n",
    "        ex_key_points.sort(key=lambda x:x.cnt,reverse=True)\n",
    "        # 筛选\n",
    "        res_keys = ex_key_points[:]\n",
    "        # res = 0\n",
    "        # for k in res_keys:\n",
    "        #     if k.cnt >= res_keys[0].cnt * 0.8:\n",
    "        #         res += 1\n",
    "        # res_keys = res_keys[:res]\n",
    "        all_keys.append(res_keys)\n",
    "    return all_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class shapelet:\n",
    "    def __init__(self,keyPoint,ylt,st,ed,length,val,sample):\n",
    "        # keyPoint 由那个keyPoint生成\n",
    "        # ylt 松弛是多少\n",
    "        # st 起始位置\n",
    "        # ed 终止位置\n",
    "        # val shapelet在序列中的实际的值\n",
    "        self.quality = None\n",
    "        self.keyPoint = keyPoint\n",
    "        self.ylt = ylt\n",
    "        self.st = st\n",
    "        self.ed = ed\n",
    "        self.length = length\n",
    "        self.val = val\n",
    "        self.sample = sample\n",
    "    def setQuality(self,quality):\n",
    "        self.quality = quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generateCandidates(s,sm,l,keyP,ylt):\n",
    "    # sm 为单个样本[维度，长度]\n",
    "    # keyP 应该为一个keyPoint\n",
    "    # ylt为松弛参数\n",
    "    candidate = []\n",
    "    if l % 2 == 1:\n",
    "        l = l // 2\n",
    "        dim = keyP.dim\n",
    "        s = s[dim]\n",
    "        for i in range(-ylt,ylt+1):\n",
    "            # 从中心点两侧的松弛长度进行计算\n",
    "            if keyP.key - i - l < 0:\n",
    "                continue\n",
    "            left = keyP.key - i - l\n",
    "            if keyP.key - i + l + 1 >= len(s):\n",
    "                continue\n",
    "            right = keyP.key - i + l + 1\n",
    "            spt = shapelet(keyPoint=keyP,ylt=ylt,st=left,ed=right - 1,length=right-left,val=s[left:right],sample=sm)\n",
    "            candidate.append(spt)\n",
    "    else:\n",
    "        l = l // 2\n",
    "        dim = keyP.dim\n",
    "        s = s[dim]\n",
    "        for i in range(-ylt,ylt+1):\n",
    "            # 从中心点两侧的松弛长度进行计算\n",
    "            if keyP.key - i - l < 0:\n",
    "                continue\n",
    "            left = keyP.key - i - l\n",
    "            if keyP.key - i + l >= len(s):\n",
    "                continue\n",
    "            right = keyP.key - i + l\n",
    "            spt = shapelet(keyPoint=keyP,ylt=ylt,st=left,ed=right - 1,length=right-left,val=s[left:right],sample=sm)\n",
    "            candidate.append(spt)\n",
    "            if keyP.key - i - l + 1< 0:\n",
    "                continue\n",
    "            left = keyP.key - i - l + 1\n",
    "            if keyP.key - i + l + 1 >= len(s):\n",
    "                continue\n",
    "            right = keyP.key - i + l + 1\n",
    "            spt = shapelet(keyPoint=keyP,ylt=ylt,st=left,ed=right - 1,length=right-left,val=s[left:right],sample=sm)\n",
    "            candidate.append(spt)\n",
    "    return candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# from sklearn import metrics\n",
    "# X = np.array([[1, 2, 1], [1, 4, 1], [1, 0 ,1], [10, 2, 5], [10, 4 ,5], [10, 0, 5]])\n",
    "# kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n",
    "# kmeans.labels_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "import collections\n",
    "def findShapeletCandidates(data,lmin,lmax,keys,ylt,odim):\n",
    "    sample_nums = data.shape[0]\n",
    "    dims = data.shape[1]\n",
    "    candidate = []\n",
    "    for sm in tqdm(range(sample_nums)):\n",
    "        s = data[sm]\n",
    "        keyList = keys[sm]\n",
    "        for k in keyList:\n",
    "            # lmin - lmax\n",
    "            for l in range(lmin,lmax+1):\n",
    "                candidate.extend(generateCandidates(s,sm,l,k,ylt))\n",
    "    dis_candidate = []\n",
    "    for i in candidate:\n",
    "        dis_candidate.append(np.array(i.val))\n",
    "    # print(dis_candidate[-1])\n",
    "    dis_candidate = np.array(dis_candidate)\n",
    "    n_clusters= 10 * dims\n",
    "    kmeans = KMeans(n_clusters,max_iter=10000).fit(dis_candidate)\n",
    "    center = kmeans.cluster_centers_\n",
    "    final_candidate = []\n",
    "    for i in center:\n",
    "        for index,j in enumerate(dis_candidate):\n",
    "            diff = list(set(i).difference(set(j)))\n",
    "            diff.extend(list(set(j).difference(set(i))))\n",
    "            if diff == []:\n",
    "                final_candidate.append(candidate[index])\n",
    "    dt = collections.defaultdict(list)\n",
    "    for i in center:\n",
    "        dt[len(i.val)].append(i)\n",
    "    return dt\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def findDistances(c,l,data):\n",
    "    # 查找获选shapelet在每个样本上的最小值\n",
    "    ds = []\n",
    "    dim = c.keyPoint.dim\n",
    "    data = np.transpose(data,axes=(1,0,2))\n",
    "    sers = data[dim]\n",
    "    for s in sers:\n",
    "        cp = [s[i : i + l] for i in range(0, len(s)-l+1, 1)]\n",
    "        ds.append(cdist([c.val],cp,metric='seuclidean').min())\n",
    "    return np.array(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def assessCandidate(ds,label):\n",
    "    class_groups = []\n",
    "    for c in np.unique(label):\n",
    "        class_groups.append(ds[label==c].tolist())\n",
    "#  返回f值\n",
    "    return f_oneway(*class_groups).statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sortByQuality(shapelets):\n",
    "    return sorted(shapelets, key=lambda s: s.quality,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "class interval:\n",
    "    def __init__(self,st,ed):\n",
    "        self.st = st\n",
    "        self.ed = ed\n",
    "    def isInclude(self,a):\n",
    "        # 是否被a包含\n",
    "        if self.st >= a.st and self.ed <= a.ed:\n",
    "            return True\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def removeSelfSimilar(shapelets):\n",
    "    ts = shapelets[:][::-1]\n",
    "    it = []\n",
    "    for x in ts:\n",
    "        it.append(interval(x.st,x.ed))\n",
    "    removeIdx = []\n",
    "    l = len(it)\n",
    "    # 修改将重叠改为包含\n",
    "    for i in range(l):\n",
    "        for j in range(i+1,l):\n",
    "            if it[i].isInclude(it[j]):\n",
    "                removeIdx.append(i)\n",
    "                break\n",
    "    res = []\n",
    "    for i in range(l):\n",
    "        if i not in removeIdx:\n",
    "            res.append(ts[i])\n",
    "\n",
    "\n",
    "    return res[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def merge(k,kShapelets,shapelets):\n",
    "    total_shapelets = kShapelets + shapelets\n",
    "    return sortByQuality(total_shapelets)[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def findShapelets(data,label,dt,k):\n",
    "    kShapelets = []\n",
    "    # l 为长度\n",
    "    for l in dt.keys():\n",
    "        # cd 是单个长度的所有样本和维度下的shaplet候选\n",
    "        cd = dt[l]\n",
    "        if len(cd) == 0:\n",
    "            continue\n",
    "        for i,c in enumerate(tqdm(cd)):\n",
    "            ds = findDistances(c,l,data)\n",
    "            quality = assessCandidate(ds,label)\n",
    "            cd[i].setQuality(quality)\n",
    "        cd = sortByQuality(cd)\n",
    "        # print(len(cd))\n",
    "        cd = removeSelfSimilar(cd)\n",
    "        # print(len(cd))\n",
    "        kShapelets = merge(k,kShapelets,cd)\n",
    "    return kShapelets\n",
    "        # print(len(cd))\n",
    "        # print(cd[0].quality,cd[1].quality,cd[-1].quality)\n",
    "    # print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_raw_ts(path, dataset):\n",
    "    path = path + \"raw//\" + dataset + \"//\"\n",
    "    # 训练集\n",
    "    x_train = np.load(path + 'X_train.npy')\n",
    "    x_train = np.transpose(x_train, axes=(0, 2, 1))\n",
    "    x_test = np.load(path + 'X_test.npy')\n",
    "    x_test = np.transpose(x_test, axes=(0, 2, 1))\n",
    "    y_train = np.load(path + 'y_train.npy')\n",
    "    y_test = np.load(path + 'y_test.npy')\n",
    "    labels = np.concatenate((y_train, y_test), axis=0)\n",
    "    nclass = int(np.amax(labels)) + 1\n",
    "    return x_train, x_test, y_train.reshape(-1), y_test.reshape(-1), nclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# target_train 为标签 data_train 为序列\n",
    "data_train, data_test, target_train, target_test, nclass = load_raw_ts(\"D://tmppro//data//\", \"UWaveGestureLibrary\")\n",
    "sample_nums = data_train.shape[0]\n",
    "dim_nums = data_train.shape[1]\n",
    "series_length = data_train.shape[2]\n",
    "test_nums = data_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "lmin = 2\n",
    "lmax = 13\n",
    "# 选取shapelet的数量\n",
    "# k = int(series_length * dim_nums)\n",
    "k = 100\n",
    "alp = 0.4\n",
    "# k = 20\n",
    "# alp = random.choice([0.3, 0.4])\n",
    "# blt = random.choice([100, 90, 80, 70, 60, 50])\n",
    "blt = 50\n",
    "# ylt = random.choice([5,6,7,8])\n",
    "ylt = 8\n",
    "dis = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(k)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#对于每个样本生成差异序列序列\n",
    "def genDiffSeries(data):\n",
    "    sample_nums = data.shape[0]\n",
    "    dim_nums = data.shape[1]\n",
    "    series_length = data.shape[2]\n",
    "    gen_data = []\n",
    "    for sn in range(sample_nums):\n",
    "        sm = data[sn]\n",
    "        res = []\n",
    "        # 先将原始的每个维度的加进入\n",
    "        for i in range(dim_nums):\n",
    "            res.append(sm[i])\n",
    "        # 再计算每个减法维度，然后依次加进去\n",
    "        for i in range(dim_nums-1):\n",
    "            for j in range(i+1,dim_nums):\n",
    "                s1 = sm[i]\n",
    "                s2 = sm[j]\n",
    "                news = [0 for _ in range(series_length)]\n",
    "                for k in range(series_length):\n",
    "                    news[k] = s1[k] - s2[k]\n",
    "                res.append(np.array(news))\n",
    "        gen_data.append(np.array(res))\n",
    "    return np.array(gen_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 3, 315)\n",
      "(120, 6, 315)\n"
     ]
    }
   ],
   "source": [
    "print(data_train.shape)\n",
    "a = genDiffSeries(data_train)\n",
    "print(a.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:06<00:00, 19.35it/s]\n"
     ]
    }
   ],
   "source": [
    "keys = selectKeys(a,alp,blt,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:02<00:00, 59.41it/s]\n",
      "C:\\Users\\ydssx\\AppData\\Local\\Temp\\ipykernel_22488\\2369650030.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  dis_candidate = np.array(dis_candidate)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;31mTypeError\u001B[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [64]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m dt \u001B[38;5;241m=\u001B[39m \u001B[43mfindShapeletCandidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43mlmin\u001B[49m\u001B[43m,\u001B[49m\u001B[43mlmax\u001B[49m\u001B[43m,\u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m,\u001B[49m\u001B[43mylt\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdim_nums\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [49]\u001B[0m, in \u001B[0;36mfindShapeletCandidates\u001B[1;34m(data, lmin, lmax, keys, ylt, odim)\u001B[0m\n\u001B[0;32m     17\u001B[0m dis_candidate \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(dis_candidate)\n\u001B[0;32m     18\u001B[0m n_clusters\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m \u001B[38;5;241m*\u001B[39m dims\n\u001B[1;32m---> 19\u001B[0m kmeans \u001B[38;5;241m=\u001B[39m \u001B[43mKMeans\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_clusters\u001B[49m\u001B[43m,\u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10000\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdis_candidate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m center \u001B[38;5;241m=\u001B[39m kmeans\u001B[38;5;241m.\u001B[39mcluster_centers_\n\u001B[0;32m     21\u001B[0m final_candidate \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[1;32mc:\\users\\ydssx\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1137\u001B[0m, in \u001B[0;36mKMeans.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   1112\u001B[0m     \u001B[38;5;124;03m\"\"\"Compute k-means clustering.\u001B[39;00m\n\u001B[0;32m   1113\u001B[0m \n\u001B[0;32m   1114\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1135\u001B[0m \u001B[38;5;124;03m        Fitted estimator.\u001B[39;00m\n\u001B[0;32m   1136\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1137\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1138\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1139\u001B[0m \u001B[43m        \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1140\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat64\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1141\u001B[0m \u001B[43m        \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mC\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1142\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1143\u001B[0m \u001B[43m        \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1144\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1146\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_params(X)\n\u001B[0;32m   1147\u001B[0m     random_state \u001B[38;5;241m=\u001B[39m check_random_state(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrandom_state)\n",
      "File \u001B[1;32mc:\\users\\ydssx\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:566\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[0;32m    564\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mValidation should be done on X, y or both.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    565\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m no_val_y:\n\u001B[1;32m--> 566\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    567\u001B[0m     out \u001B[38;5;241m=\u001B[39m X\n\u001B[0;32m    568\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_y:\n",
      "File \u001B[1;32mc:\\users\\ydssx\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:746\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001B[0m\n\u001B[0;32m    744\u001B[0m         array \u001B[38;5;241m=\u001B[39m array\u001B[38;5;241m.\u001B[39mastype(dtype, casting\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munsafe\u001B[39m\u001B[38;5;124m\"\u001B[39m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    745\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 746\u001B[0m         array \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    747\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ComplexWarning \u001B[38;5;28;01mas\u001B[39;00m complex_warning:\n\u001B[0;32m    748\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    749\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mComplex data not supported\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(array)\n\u001B[0;32m    750\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcomplex_warning\u001B[39;00m\n",
      "File \u001B[1;32mc:\\users\\ydssx\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\core\\_asarray.py:102\u001B[0m, in \u001B[0;36masarray\u001B[1;34m(a, dtype, order, like)\u001B[0m\n\u001B[0;32m     99\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m like \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _asarray_with_like(a, dtype\u001B[38;5;241m=\u001B[39mdtype, order\u001B[38;5;241m=\u001B[39morder, like\u001B[38;5;241m=\u001B[39mlike)\n\u001B[1;32m--> 102\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mValueError\u001B[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "dt = findShapeletCandidates(a,lmin,lmax,keys,ylt,dim_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "kshapelets = findShapelets(a,target_train,dt,k)\n",
    "k = len(kshapelets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(k)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for shape in kshapelets:\n",
    "    if shape.length == 10:\n",
    "        plt.plot(shape.val)\n",
    "plt.title(\"Discriminatory Shapelets\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "搞个判断标准，选择较好的候选shapelet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = np.zeros((sample_nums,k))\n",
    "for i,sp in enumerate(tqdm(kshapelets)):\n",
    "    Ds = findDistances(sp,sp.length,a)\n",
    "    dataset[:,i] = Ds\n",
    "dataset = np.nan_to_num(dataset)\n",
    "# print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = np.zeros((test_nums,k))\n",
    "b = genDiffSeries(data_test)\n",
    "for i,sp in enumerate(tqdm(kshapelets)):\n",
    "    Ds = findDistances(sp,sp.length,b)\n",
    "    dataset_test[:,i] = Ds\n",
    "dataset_test = np.nan_to_num(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "# scc = sc.fit_transform(dataset)\n",
    "# np.set_printoptions(threshold=np.inf)\n",
    "# print(dataset)\n",
    "# print(scc)\n",
    "\n",
    "# model = LogisticRegressionCV(max_iter=100000).fit(sc.fit_transform(dataset),target_train)\n",
    "model = LinearSVC(max_iter=100000).fit(sc.fit_transform(dataset),target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(target_train,model.predict(sc.transform(dataset))))\n",
    "print(accuracy_score(target_train,model.predict(sc.transform(dataset))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(target_test,model.predict(sc.transform(dataset_test))))\n",
    "print(accuracy_score(target_test,model.predict(sc.transform(dataset_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "todo:\n",
    "优先选择样本产生多的？？"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}