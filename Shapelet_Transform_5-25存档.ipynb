{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import heapq as hq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# 计算方差窗口的大小\n",
    "def computeWinSize(length, b):\n",
    "    if 0 < length <= b:\n",
    "        return 1\n",
    "    else:\n",
    "        return length // b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# 计算标准差数组\n",
    "def computeStdArr(series, b):\n",
    "    l = len(series)\n",
    "    # 窗口下取整\n",
    "    w = computeWinSize(l, b)\n",
    "    # print(w)\n",
    "    res = []\n",
    "    for i in range(w, l - w):\n",
    "        win_arr = [0 for i in range(2 * w + 1)]\n",
    "        cnt = 0\n",
    "        for j in range(i - w, w + i + 1):\n",
    "            win_arr[cnt] = series[j]\n",
    "            cnt += 1\n",
    "        std = np.std(win_arr, ddof=0)\n",
    "        res.append(std)\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# 选择L*α最大的点的下标,，保留下标\n",
    "def selectLargePoint(series, a):\n",
    "    l = len(series)\n",
    "    # 生成l*a个\n",
    "    res = hq.nlargest(int(l * a), range(l), key=lambda x: series[x])\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# 判断是否为波峰波谷\n",
    "def isPeakOrValley(std_arr, index, b):\n",
    "    win_size = computeWinSize(len(std_arr), b)\n",
    "    flag = False\n",
    "    if win_size == 1:\n",
    "        if ((std_arr[index] > std_arr[index - 1] and std_arr[index] > std_arr[index + 1]) or (\n",
    "                std_arr[index] < std_arr[index - 1] and std_arr[index] < std_arr[index + 1])):\n",
    "            flag = True\n",
    "    elif win_size == 2:\n",
    "        if ((std_arr[index] >= std_arr[index - 1] and std_arr[index] > std_arr[index - 2] and std_arr[index] >= std_arr[\n",
    "            index + 1] and std_arr[index] > std_arr[index + 2])\n",
    "                or\n",
    "                (std_arr[index] <= std_arr[index - 1] and std_arr[index] < std_arr[index - 2] and std_arr[index] <=\n",
    "                 std_arr[\n",
    "                     index + 1]) and std_arr[index] < std_arr[index + 2]):\n",
    "            flag = True\n",
    "    elif win_size == 3:\n",
    "        if ((std_arr[index] >= std_arr[index - 1] and std_arr[index] > std_arr[index - 2] and std_arr[index] > std_arr[\n",
    "            index - 3]\n",
    "             and std_arr[index] >= std_arr[index + 1] and std_arr[index] > std_arr[index + 2] and std_arr[index] >\n",
    "             std_arr[\n",
    "                 index + 3])\n",
    "                or\n",
    "                (std_arr[index] <= std_arr[index - 1] and std_arr[index] < std_arr[index - 2] and std_arr[index] <\n",
    "                 std_arr[index - 3]) and std_arr[index] <= std_arr[index + 1] and std_arr[index] < std_arr[\n",
    "                    index + 2] and std_arr[index] < std_arr[index + 3]):\n",
    "            flag = True\n",
    "    elif win_size == 4:\n",
    "        if ((std_arr[index] >= std_arr[index - 1] and std_arr[index] > std_arr[index - 2] and std_arr[index] > std_arr[\n",
    "            index - 3] and std_arr[index] > std_arr[index - 4]\n",
    "             and std_arr[index] >= std_arr[index + 1] and std_arr[index] > std_arr[index + 2] and std_arr[index] >\n",
    "             std_arr[\n",
    "                 index + 3] and std_arr[index] > std_arr[index + 4])\n",
    "                or\n",
    "                (std_arr[index] <= std_arr[index - 1] and std_arr[index] < std_arr[index - 2] and std_arr[index] <\n",
    "                 std_arr[\n",
    "                     index - 3] and std_arr[index] < std_arr[index - 4]\n",
    "                 and std_arr[index] <= std_arr[index + 1] and std_arr[index] < std_arr[index + 2] and std_arr[index] <\n",
    "                 std_arr[index + 3] and std_arr[index] < std_arr[index + 4])):\n",
    "            flag = True\n",
    "    else:\n",
    "        if ((std_arr[index] > std_arr[index - 1] and std_arr[index] > std_arr[index - 2] and std_arr[index] > std_arr[\n",
    "            index - 3] and std_arr[index] > std_arr[index - 4] and std_arr[index] > std_arr[index - 5]\n",
    "             and std_arr[index] > std_arr[index + 1] and std_arr[index] > std_arr[index + 2] and std_arr[index] >\n",
    "             std_arr[\n",
    "                 index + 3] and std_arr[index] > std_arr[index + 4] and std_arr[index] > std_arr[index + 5])\n",
    "                or\n",
    "                (std_arr[index] < std_arr[index - 1] and std_arr[index] < std_arr[index - 2] and std_arr[index] <\n",
    "                 std_arr[\n",
    "                     index - 3] and std_arr[index] < std_arr[index - 4] and std_arr[index] < std_arr[index - 5]\n",
    "                 and std_arr[index] < std_arr[index + 1] and std_arr[index] < std_arr[index + 2] and std_arr[index] <\n",
    "                 std_arr[\n",
    "                     index + 3] and std_arr[index] < std_arr[index + 4] and std_arr[index] < std_arr[index + 5])):\n",
    "            flag = True\n",
    "    return flag\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# 找到所有合适的区间\n",
    "def fitPoint(stdA, indexA, b):\n",
    "    w = computeWinSize(len(stdA), b)\n",
    "    l = len(indexA)\n",
    "    res = []\n",
    "    for i in range(0, l):\n",
    "        val = indexA[i]\n",
    "        if w <= val < l - w:\n",
    "            if isPeakOrValley(stdA, val, b):\n",
    "                res.append(val + 2 * w + 1)\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# 提取特征关键点\n",
    "def extractFeaturePoint(arr, a, b):\n",
    "    stdArrOne = computeStdArr(arr, b)\n",
    "    stdArrTwo = computeStdArr(stdArrOne, b)\n",
    "    largePoint = selectLargePoint(stdArrTwo, a)\n",
    "    indexArr = fitPoint(stdArrTwo, largePoint, b)\n",
    "    return indexArr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# 判断有几个关键点与它相近\n",
    "def closeNums(keyList,key,threshold):\n",
    "    cnt = 0\n",
    "    cnt += keyList.count(key)\n",
    "    for i in range(1,threshold):\n",
    "        a = key + i\n",
    "        b = key - i\n",
    "        cnt += keyList.count(a)\n",
    "        cnt += keyList.count(b)\n",
    "    return cnt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "class keyPoint:\n",
    "    def __init__(self,key,cnt,dim):\n",
    "        self.key = key\n",
    "        self.cnt = cnt\n",
    "        self.dim = dim"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "# 找到较为相近的关键点\n",
    "def selectKeys(data,alp,blt,ylt):\n",
    "    # 原始data顺序 样本数 维度数 序列长度\n",
    "    dim_nums = data.shape[1]\n",
    "    sample_nums = data.shape[0]\n",
    "    all_keys = []\n",
    "    for sm in tqdm(range(sample_nums)):\n",
    "        one_sample  = data[sm]\n",
    "        key_points = []\n",
    "        key_list = []\n",
    "        ex_key_points = []\n",
    "        for dn in range(dim_nums):\n",
    "            keys = extractFeaturePoint(one_sample[dn],alp,blt)\n",
    "            key_points.append(keys)\n",
    "            key_list.extend(keys)\n",
    "        for dn in range(dim_nums):\n",
    "            kl = key_points[dn]\n",
    "            ekl = []\n",
    "            for k in kl:\n",
    "                cnt = closeNums(key_list,k,ylt)\n",
    "                ekl.append(keyPoint(k,cnt,dn))\n",
    "            ex_key_points.extend(ekl)\n",
    "        # 取前30%的70% 和 后70%的30%\n",
    "        ex_key_points.sort(key=lambda x:x.cnt,reverse=True)\n",
    "        # print(len(ex_key_points))\n",
    "        length = len(ex_key_points)\n",
    "        # 前30%\n",
    "        preLength = int(0.1 * length)\n",
    "        preKey = ex_key_points[:preLength+1]\n",
    "        # # 后70%\n",
    "        # aftLength = length - preLength\n",
    "        # aftKey = ex_key_points[preLength+1:]\n",
    "        # 取前30%的70%\n",
    "        # preKey = random.sample(preKey,int(preLength * 0.7))\n",
    "        # aftKey = random.sample(aftKey,int(aftLength * 0.3))\n",
    "        ex_key_points = []\n",
    "        ex_key_points.extend(preKey)\n",
    "        # ex_key_points.extend(aftKey)\n",
    "        # print(len(ex_key_points))\n",
    "        all_keys.append(ex_key_points)\n",
    "    return all_keys"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "class shapelet:\n",
    "    def __init__(self,keyPoint,ylt,st,ed,length,val,sample):\n",
    "        # keyPoint 由那个keyPoint生成\n",
    "        # ylt 松弛是多少\n",
    "        # st 起始位置\n",
    "        # ed 终止位置\n",
    "        # val shapelet在序列中的实际的值\n",
    "        self.quality = None\n",
    "        self.keyPoint = keyPoint\n",
    "        self.ylt = ylt\n",
    "        self.st = st\n",
    "        self.ed = ed\n",
    "        self.length = length\n",
    "        self.val = val\n",
    "        self.sample = sample\n",
    "    def setQuality(self,quality):\n",
    "        self.quality = quality"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "def generateCandidates(s,sm,l,keyP,ylt):\n",
    "    # sm 为单个样本[维度，长度]\n",
    "    # keyP 应该为一个keyPoint\n",
    "    # ylt为松弛参数\n",
    "    candidate = []\n",
    "    if l % 2 == 1:\n",
    "        l = l // 2\n",
    "        dim = keyP.dim\n",
    "        s = s[dim]\n",
    "        for i in range(-ylt,ylt+1):\n",
    "            # 从中心点两侧的松弛长度进行计算\n",
    "            if keyP.key - i - l < 0:\n",
    "                continue\n",
    "            left = keyP.key - i - l\n",
    "            if keyP.key - i + l + 1 >= len(s):\n",
    "                continue\n",
    "            right = keyP.key - i + l + 1\n",
    "            spt = shapelet(keyPoint=keyP,ylt=ylt,st=left,ed=right - 1,length=right-left,val=s[left:right],sample=sm)\n",
    "            candidate.append(spt)\n",
    "    else:\n",
    "        l = l // 2\n",
    "        dim = keyP.dim\n",
    "        s = s[dim]\n",
    "        for i in range(-ylt,ylt+1):\n",
    "            # 从中心点两侧的松弛长度进行计算\n",
    "            if keyP.key - i - l < 0:\n",
    "                continue\n",
    "            left = keyP.key - i - l\n",
    "            if keyP.key - i + l >= len(s):\n",
    "                continue\n",
    "            right = keyP.key - i + l\n",
    "            spt = shapelet(keyPoint=keyP,ylt=ylt,st=left,ed=right - 1,length=right-left,val=s[left:right],sample=sm)\n",
    "            candidate.append(spt)\n",
    "            if keyP.key - i - l + 1< 0:\n",
    "                continue\n",
    "            left = keyP.key - i - l + 1\n",
    "            if keyP.key - i + l + 1 >= len(s):\n",
    "                continue\n",
    "            right = keyP.key - i + l + 1\n",
    "            spt = shapelet(keyPoint=keyP,ylt=ylt,st=left,ed=right - 1,length=right-left,val=s[left:right],sample=sm)\n",
    "            candidate.append(spt)\n",
    "    return candidate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "import collections\n",
    "def findShapeletCandidates(data,lmin,lmax,keys,ylt):\n",
    "    sample_nums = data.shape[0]\n",
    "    candidate = []\n",
    "    for sm in tqdm(range(sample_nums)):\n",
    "        s = data[sm]\n",
    "        keyList = keys[sm]\n",
    "        for k in keyList:\n",
    "            # lmin - lmax\n",
    "            for l in range(lmin,lmax+1):\n",
    "                candidate.extend(generateCandidates(s,sm,l,k,ylt))\n",
    "    # print(len(candidate))\n",
    "    dt = collections.defaultdict(list)\n",
    "    for cd in candidate:\n",
    "        dt[cd.length].append(cd)\n",
    "    return dt\n",
    "    # print(dt.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "def findDistances(c,l,data):\n",
    "    # 查找获选shapelet在每个样本上的最小值\n",
    "    ds = []\n",
    "    dim = c.keyPoint.dim\n",
    "    data = np.transpose(data,axes=(1,0,2))\n",
    "    sers = data[dim]\n",
    "    for s in sers:\n",
    "        cp = [s[i : i + l] for i in range(0, len(s)-l+1, 1)]\n",
    "        ds.append(cdist([c.val],cp,metric='seuclidean').min())\n",
    "    return np.array(ds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "def assessCandidate(ds,label):\n",
    "    class_groups = []\n",
    "    for c in np.unique(label):\n",
    "        class_groups.append(ds[label==c].tolist())\n",
    "#  返回f值\n",
    "    return f_oneway(*class_groups).statistic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "def sortByQuality(shapelets):\n",
    "    return sorted(shapelets, key=lambda s: s.quality,reverse=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "def removeSelfSimilar(shapelets):\n",
    "    ts = shapelets[:][::-1]\n",
    "    it = []\n",
    "    for x in ts:\n",
    "        it.append(pd.Interval(x.st,x.ed,closed='both'))\n",
    "    removeIdx = []\n",
    "    l = len(it)\n",
    "    for i in range(l):\n",
    "        for j in range(i+1,l):\n",
    "            if it[i].overlaps(it[j]):\n",
    "                removeIdx.append(i)\n",
    "                break\n",
    "    res = []\n",
    "    for i in range(l):\n",
    "        if i not in removeIdx:\n",
    "            res.append(ts[i])\n",
    "    return res[::-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "def merge(k,kShapelets,shapelets):\n",
    "    total_shapelets = kShapelets + shapelets\n",
    "    return sortByQuality(total_shapelets)[:k]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "def findShapelets(data,label,dt,k):\n",
    "    kShapelets = []\n",
    "    # l 为长度\n",
    "    for l in dt.keys():\n",
    "        # cd 是单个长度的所有样本和维度下的shaplet候选\n",
    "        cd = dt[l]\n",
    "        for i,c in enumerate(tqdm(cd)):\n",
    "            ds = findDistances(c,l,data)\n",
    "            quality = assessCandidate(ds,label)\n",
    "            cd[i].setQuality(quality)\n",
    "        cd = sortByQuality(cd)\n",
    "        # print(len(cd))\n",
    "        cd = removeSelfSimilar(cd)\n",
    "        kShapelets = merge(k,kShapelets,cd)\n",
    "    return kShapelets\n",
    "        # print(len(cd))\n",
    "        # print(cd[0].quality,cd[1].quality,cd[-1].quality)\n",
    "    # print(k)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "# np.vstack([[2,3,4,5],[1,2,3,4],[1,2,3,5]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "# a = cdist([[1,2,3,4]],[[2,3,4,10],[1,2,3,4],[1,2,3,5]],metric='euclidean').min()\n",
    "# print(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# def SelectShapelet(data,label,lmin,lmax,alp,blt,ylt):\n",
    "#     # 原始data顺序 样本数 维度数 序列长度\n",
    "#     data = np.transpose(data,axes=(1,0,2))\n",
    "#     # 现在data顺序 维度数 样本数 序列长度\n",
    "#     dim_nums = data.shape[0]\n",
    "#     sample_nums = data.shape[1]\n",
    "#     for dn in tqdm(range(dim_nums)):\n",
    "#         T = data[dn]\n",
    "#         keyPoints = []\n",
    "#         for sm in range(sample_nums):\n",
    "#             keyPoints.append(extractFeaturePoint(data[dn][sm],alp,blt))\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#         # print(keyPoints)\n",
    "#         precompute_Wl = {l : create_Wl(T,l,keyPoints,sample_nums,ylt) for l in np.arange(lmin,lmax+1)}\n",
    "#\n",
    "#         kShapelets = []\n",
    "#         for i,Ti in enumerate(T):\n",
    "#             shapelets = []\n",
    "#             for l in np.arange(lmin,lmax+1):\n",
    "#                 # S为所有的长度\n",
    "#                 Al = precompute_Wl[l]\n",
    "#                 Wl,Pl = Al[0],Al[1]\n",
    "#                 for index,S in enumerate(Wl[i]):\n",
    "#                      # 和所有样本上的候选者比较\n",
    "#                     #  S 区间，keypoint，松弛长度\n",
    "#                     # Ds,Indx = findDistances(S,Wl)\n",
    "#\n",
    "#                     Ds = findDistances(S,Wl)\n",
    "#                     quality = assessCandidate(Ds,label)\n",
    "#                     #  区间值 度量  区间 关键点\n",
    "#                     shapelets.append((S,quality,pd.Interval(Pl[index][1],Pl[index][2]-1,closed='both'),Pl[index][0]))\n",
    "#             shapelets = sortByQuality(shapelets)\n",
    "#             shapelets = removeSelfSimilar(shapelets)\n",
    "#             kShapelets = merge(k,kShapelets,shapelets)\n",
    "#         print(kShapelets)\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "def load_raw_ts(path, dataset):\n",
    "    path = path + \"raw//\" + dataset + \"//\"\n",
    "    # 训练集\n",
    "    x_train = np.load(path + 'X_train.npy')\n",
    "    x_train = np.transpose(x_train, axes=(0, 2, 1))\n",
    "    x_test = np.load(path + 'X_test.npy')\n",
    "    x_test = np.transpose(x_test, axes=(0, 2, 1))\n",
    "    y_train = np.load(path + 'y_train.npy')\n",
    "    y_test = np.load(path + 'y_test.npy')\n",
    "    labels = np.concatenate((y_train, y_test), axis=0)\n",
    "    nclass = int(np.amax(labels)) + 1\n",
    "    return x_train, x_test, y_train.reshape(-1), y_test.reshape(-1), nclass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "# target_train 为标签 data_train 为序列\n",
    "data_train, data_test, target_train, target_test, nclass = load_raw_ts(\"D://tmppro//data//\", \"BasicMotions\")\n",
    "sample_nums = data_train.shape[0]\n",
    "dim_nums = data_train.shape[1]\n",
    "series_length = data_train.shape[2]\n",
    "test_nums = data_test.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "lmin = 3\n",
    "lmax = int(series_length /2)\n",
    "# 选取shapelet的数量\n",
    "k = int(series_length * dim_nums /2)\n",
    "alp = 0.5\n",
    "# k = 20\n",
    "# alp = random.choice([0.3, 0.4])\n",
    "# blt = random.choice([100, 90, 80, 70, 60, 50])\n",
    "blt = 50\n",
    "# ylt = random.choice([5,6,7,8])\n",
    "ylt = 5\n",
    "dis = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "#对于每个样本生成差异序列序列\n",
    "def genDiffSeries(data):\n",
    "    sample_nums = data.shape[0]\n",
    "    dim_nums = data.shape[1]\n",
    "    series_length = data.shape[2]\n",
    "    gen_data = []\n",
    "    for sn in range(sample_nums):\n",
    "        sm = data[sn]\n",
    "        res = []\n",
    "        # 先将原始的每个维度的加进入\n",
    "        for i in range(dim_nums):\n",
    "            res.append(sm[i])\n",
    "        # 再计算每个减法维度，然后依次加进去\n",
    "        for i in range(dim_nums-1):\n",
    "            for j in range(i+1,dim_nums):\n",
    "                s1 = sm[i]\n",
    "                s2 = sm[j]\n",
    "                news = [0 for _ in range(series_length)]\n",
    "                for k in range(series_length):\n",
    "                    news[k] = s1[k] - s2[k]\n",
    "                res.append(np.array(news))\n",
    "        gen_data.append(np.array(res))\n",
    "    return np.array(gen_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7494, 2, 8)\n",
      "(7494, 3, 8)\n"
     ]
    }
   ],
   "source": [
    "print(data_train.shape)\n",
    "a = genDiffSeries(data_train)\n",
    "print(a.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "# keys = selectKeys(data_train,alp,blt,2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# dt = findShapeletCandidates(data_train,lmin,lmax,keys,ylt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "# kshapelets = findShapelets(data_train,target_train,dt,k)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "# ds = [1,2,3,4]\n",
    "# print(ds[target_train==2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "# print(kshapelets[0].val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for shape in kshapelets:\n",
    "#     plt.plot(shape.val)\n",
    "# plt.title(\"Discriminatory Shapelets\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataset = np.zeros((sample_nums,k))\n",
    "# for i,sp in enumerate(tqdm(kshapelets)):\n",
    "#     Ds = findDistances(sp,sp.length,data_train)\n",
    "#     dataset[:,i] = Ds\n",
    "# # print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "# print(k)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_test = np.zeros((test_nums,k))\n",
    "# for i,sp in enumerate(tqdm(kshapelets)):\n",
    "#     Ds = findDistances(sp,sp.length,data_test)\n",
    "#     dataset_test[:,i] = Ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sc = StandardScaler()\n",
    "# # model = LogisticRegressionCV(max_iter=100000).fit(sc.fit_transform(dataset),target_train)\n",
    "# model = LinearSVC(max_iter=10000,multi_class='crammer_singer').fit(sc.fit_transform(dataset),target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(classification_report(target_train,model.predict(sc.transform(dataset))))\n",
    "# # print(accuracy_score(target_train,model.predict(sc.transform(dataset))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(classification_report(target_test,model.predict(sc.transform(dataset_test))))\n",
    "# print(accuracy_score(target_test,model.predict(sc.transform(dataset_test))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}